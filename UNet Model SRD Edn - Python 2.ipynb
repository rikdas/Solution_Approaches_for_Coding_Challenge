{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"UNet Model SRD Edn - Python 2.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python2","display_name":"Python 2"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uajTGigy9nCl","executionInfo":{"status":"ok","timestamp":1629477663333,"user_tz":-330,"elapsed":3996,"user":{"displayName":"Rik Das","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgTTiRJEQsnHczOK7jiY2UY6jbgb3hPYBY2YaRJ=s64","userId":"00444844359278086917"}},"outputId":"4a6034d3-217d-487e-b606-c464f6968bb6"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FyezvYb0-7cb","executionInfo":{"status":"ok","timestamp":1629477724573,"user_tz":-330,"elapsed":627,"user":{"displayName":"Rik Das","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgTTiRJEQsnHczOK7jiY2UY6jbgb3hPYBY2YaRJ=s64","userId":"00444844359278086917"}}},"source":["import os\n","\n","os.chdir(\"/content/drive/MyDrive/Satellite Image Segmentation using UNET-20210819T073450Z-001/Satellite Image Segmentation using UNET\")"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xbZVTzZN_M1n","executionInfo":{"status":"ok","timestamp":1629477730368,"user_tz":-330,"elapsed":660,"user":{"displayName":"Rik Das","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgTTiRJEQsnHczOK7jiY2UY6jbgb3hPYBY2YaRJ=s64","userId":"00444844359278086917"}},"outputId":"4f4a9248-bf48-4c38-dc97-020f3b81a1f8"},"source":["print os.getcwd()"],"execution_count":11,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/Satellite Image Segmentation using UNET-20210819T073450Z-001/Satellite Image Segmentation using UNET\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"iUSPUCgDDCMS"},"source":["## Train"]},{"cell_type":"code","metadata":{"id":"lI7vks9fDD1c","colab":{"base_uri":"https://localhost:8080/","height":370},"executionInfo":{"status":"error","timestamp":1629477751529,"user_tz":-330,"elapsed":15156,"user":{"displayName":"Rik Das","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgTTiRJEQsnHczOK7jiY2UY6jbgb3hPYBY2YaRJ=s64","userId":"00444844359278086917"}},"outputId":"97d7eb16-b32e-4ba9-f70b-024817286962"},"source":["import numpy as np\n","import pandas as pd\n","import keras\n","from keras.models import Model\n","from keras.layers import *\n","from keras import initializers\n","from keras import optimizers\n","from import_data import load_data\n","import os\n","from deleteArgs import deleteArgs\n","\n","# Designed UNet Model for Semantic Segmentation.\n","def unet_model():\n","    input_layer = Input(shape=(None, None, 3))\n","    convolutional_layer_1 = Conv2D(filters=64, kernel_size=[3,3], kernel_initializer=initializers.he_normal(seed=1), activation=\"relu\", padding=\"same\")(input_layer)\n","    convolutional_layer_2 = Conv2D(filters=64, kernel_size=[3,3], kernel_initializer=initializers.he_normal(seed=1), activation=\"relu\", padding=\"same\")(convolutional_layer_1)\n","    pooling_layer_1 = MaxPooling2D(pool_size=[2,2], strides=2)(convolutional_layer_2)\n","    convolutional_layer_3 = Conv2D(filters=128, kernel_size=[3,3], kernel_initializer=initializers.he_normal(seed=1), activation=\"relu\", padding=\"same\")(pooling_layer_1)\n","    convolutional_layer_4 = Conv2D(filters=128, kernel_size=[3,3], kernel_initializer=initializers.he_normal(seed=1), activation=\"relu\", padding=\"same\")(convolutional_layer_3)\n","    pooling_layer_2 = MaxPooling2D(pool_size=[2,2], strides=2)(convolutional_layer_4)\n","    convolutional_layer_5 =  Conv2D(filters=256, kernel_size=[3,3], kernel_initializer=initializers.he_normal(seed=1), activation=\"relu\", padding=\"same\")(pooling_layer_2)\n","    convolutional_layer_6 = Conv2D(filters=256, kernel_size=[3,3], kernel_initializer=initializers.he_normal(seed=1), activation=\"relu\", padding=\"same\")(convolutional_layer_5)\n","    pooling_layer_3 = MaxPooling2D(pool_size=[2,2], strides=2)(convolutional_layer_6)\n","    convolutional_layer_7 = Conv2D(filters=512, kernel_size=[3,3], kernel_initializer=initializers.he_normal(seed=1), activation=\"relu\", padding=\"same\")(pooling_layer_3)\n","    convolutional_layer_8 = Conv2D(filters=512, kernel_size=[3,3], kernel_initializer=initializers.he_normal(seed=1), activation=\"relu\", padding=\"same\")(convolutional_layer_7)\n","    pooling_layer_4 = MaxPooling2D(pool_size=[2,2], strides=2)(convolutional_layer_8)\n","    convolutional_layer_9 = Conv2D(filters=1024, kernel_size=[3,3], kernel_initializer=initializers.he_normal(seed=1), activation=\"relu\", padding=\"same\")(pooling_layer_4)\n","    convolutional_layer_10 = Conv2D(filters=1024, kernel_size=[3,3], kernel_initializer=initializers.he_normal(seed=1), activation=\"relu\", padding=\"same\")(convolutional_layer_9)\n","    transpose_convolutional_layer_1 = Conv2DTranspose(filters=512, kernel_size=[2,2], strides=(2,2), kernel_initializer=initializers.he_normal(seed=1))(convolutional_layer_10)\n","    merged_layer_1 = concatenate([convolutional_layer_8, transpose_convolutional_layer_1], axis=3)\n","    convolutional_layer_11 = Conv2D(filters=512, kernel_size=[3,3], kernel_initializer=initializers.he_normal(seed=1), activation=\"relu\", padding=\"same\")(merged_layer_1)\n","    convolutional_layer_12 = Conv2D(filters=512, kernel_size=[3,3], kernel_initializer=initializers.he_normal(seed=1), activation=\"relu\", padding=\"same\")(convolutional_layer_11)\n","    transpose_convolutional_layer_2 = Conv2DTranspose(filters=256, kernel_size=[2,2], strides=(2,2), kernel_initializer=initializers.he_normal(seed=1))(convolutional_layer_12)\n","    merged_layer_2 = concatenate([convolutional_layer_6, transpose_convolutional_layer_2], axis=3)\n","    convolutional_layer_13 = Conv2D(filters=256, kernel_size=[3,3], kernel_initializer=initializers.he_normal(seed=1), activation=\"relu\", padding=\"same\")(merged_layer_2)\n","    convolutional_layer_14 = Conv2D(filters=256, kernel_size=[3,3], kernel_initializer=initializers.he_normal(seed=1), activation=\"relu\", padding=\"same\")(convolutional_layer_13)\n","    transpose_convolutional_layer_3 = Conv2DTranspose(filters=128, kernel_size=[2,2], strides=(2,2), kernel_initializer=initializers.he_normal(seed=1))(convolutional_layer_14)\n","    merged_layer_3 = concatenate([convolutional_layer_4, transpose_convolutional_layer_3], axis=3)\n","    convolutional_layer_15 = Conv2D(filters=128, kernel_size=[3,3], kernel_initializer=initializers.he_normal(seed=1), activation=\"relu\", padding=\"same\")(merged_layer_3)\n","    convolutional_layer_16 = Conv2D(filters=128, kernel_size=[3,3], kernel_initializer=initializers.he_normal(seed=1), activation=\"relu\", padding=\"same\")(convolutional_layer_15)\n","    transpose_convolutional_layer_4 = Conv2DTranspose(filters=64, kernel_size=[2,2], strides=(2,2), kernel_initializer=initializers.he_normal(seed=1))(convolutional_layer_16)\n","    merged_layer_4 = concatenate([convolutional_layer_2, transpose_convolutional_layer_4], axis=3)\n","    convolutional_layer_17 = Conv2D(filters=64, kernel_size=[3,3], kernel_initializer=initializers.he_normal(seed=1), activation=\"relu\", padding=\"same\")(merged_layer_4)\n","    convolutional_layer_18 = Conv2D(filters=64, kernel_size=[3,3], kernel_initializer=initializers.he_normal(seed=1), activation=\"relu\", padding=\"same\")(convolutional_layer_17)\n","    convolutional_layer_19 = Conv2D(filters=2, kernel_size=[3,3], kernel_initializer=initializers.he_normal(seed=1), activation=\"relu\", padding=\"same\")(convolutional_layer_18)\n","    convolutional_layer_20 = Conv2D(filters=1, kernel_size=[1,1], activation=\"sigmoid\")(convolutional_layer_19)\n","    model = Model(input=input_layer, output=convolutional_layer_20)\n","    model.compile(loss=\"binary_crossentropy\", optimizer=optimizers.Adam(lr=0.000001), metrics=['accuracy'])\n","    return model\n","\n","images, labels = load_data(mode=\"Train\")\n","model = unet_model()\n","print model.summary()\n","pd.DataFrame(model.fit(images,labels, epochs=5, verbose=1).history).to_csv(\"Saved_Model/history.csv\")\n","model.save(\"Saved_Model/trained_model.h5\")\n","deleteArgs()"],"execution_count":12,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)","\u001b[0;32m<ipython-input-12-2dd93460d807>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munet_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/My Drive/Satellite Image Segmentation using UNET-20210819T073450Z-001/Satellite Image Segmentation using UNET/import_data.py\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(mode)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m# mode = \"Test\", returns the raw test images, label name, image height, and image width.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"Train\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mcreateArgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mimages_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"data/raw\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mlabels_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"data/gt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/My Drive/Satellite Image Segmentation using UNET-20210819T073450Z-001/Satellite Image Segmentation using UNET/import_data.py\u001b[0m in \u001b[0;36mcreateArgs\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0mgetArgumented\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/My Drive/Satellite Image Segmentation using UNET-20210819T073450Z-001/Satellite Image Segmentation using UNET/import_data.py\u001b[0m in \u001b[0;36mgetArgumented\u001b[0;34m(IMGR, IMGG)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mimrR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data/raw/1'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mIMGR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mimrG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data/gt/1'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mIMGG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreateArgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python2.7/dist-packages/PIL/Image.pyc\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   1926\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1927\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1928\u001b[0;31m             \u001b[0msave_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1929\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1930\u001b[0m             \u001b[0;31m# do what we can to clean up\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python2.7/dist-packages/PIL/JpegImagePlugin.pyc\u001b[0m in \u001b[0;36m_save\u001b[0;34m(im, fp, filename)\u001b[0m\n\u001b[1;32m    744\u001b[0m                   len(extra) + 1)\n\u001b[1;32m    745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 746\u001b[0;31m     \u001b[0mImageFile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"jpeg\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrawmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbufsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    747\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python2.7/dist-packages/PIL/ImageFile.pyc\u001b[0m in \u001b[0;36m_save\u001b[0;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[1;32m    506\u001b[0m                 \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode_to_pyfd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m                 \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode_to_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbufsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoder error %d when writing image file\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"2Mp_6kirsfyM"},"source":["import numpy as np\n","import pandas as pd\n","import keras\n","from keras.models import Model\n","from keras.layers import *\n","from keras import initializers\n","from keras import optimizers\n","from import_data import load_data\n","import os\n","from deleteArgs import deleteArgs"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Tff4AxBVC6sI"},"source":["## Predict"]},{"cell_type":"code","metadata":{"id":"B_dERj68AF7k","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629473332709,"user_tz":-330,"elapsed":51321,"user":{"displayName":"Rik Das","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgTTiRJEQsnHczOK7jiY2UY6jbgb3hPYBY2YaRJ=s64","userId":"00444844359278086917"}},"outputId":"153a8c92-6932-43be-b278-d76928dbc4f6"},"source":["import numpy as np\n","from import_data import load_data\n","from PIL import Image\n","import keras\n","from keras.models import Model, load_model\n","\n","# Load trained unet model\n","loaded_model = load_model(\"Saved_Model/trained_model.h5\")\n","loaded_model.set_weights(loaded_model.get_weights())\n","# Retrieve raw test images, label_name, height, and width.\n","images, label_names, height, width = load_data(mode=\"Test\")\n","print(len(images))\n","for i in range(len(images)):\n","    img = images[i]\n","    # (height, width, channels) -> (1, height, width, channels)\n","    img = np.expand_dims(img, axis=0)\n","    prediction = loaded_model.predict(img, verbose=1)\n","    prediction = np.squeeze(prediction)\n","    # Generate binary mask by rounding up values.\n","    prediction = np.round(prediction)\n","    prediction = prediction * 255.\n","    # Generate image.\n","    img = Image.fromarray(prediction)\n","    if img.mode != 'RGB':\n","        img = img.convert('RGB')\n","    # Resize the image to original size.\n","    img = img.resize((width[i], height[i]), Image.ANTIALIAS)\n","    print img.size\n","    img.save(label_names[i])\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["32\n","1/1 [==============================] - 1s 1s/step\n","(250, 250)\n","1/1 [==============================] - 0s 57ms/step\n","(250, 250)\n","1/1 [==============================] - 0s 56ms/step\n","(250, 250)\n","1/1 [==============================] - 0s 57ms/step\n","(250, 250)\n","1/1 [==============================] - 0s 57ms/step\n","(250, 250)\n","1/1 [==============================] - 0s 68ms/step\n","(250, 250)\n","1/1 [==============================] - 0s 84ms/step\n","(250, 250)\n","1/1 [==============================] - 0s 84ms/step\n","(250, 250)\n","1/1 [==============================] - 0s 84ms/step\n","(250, 250)\n","1/1 [==============================] - 0s 85ms/step\n","(250, 250)\n","1/1 [==============================] - 0s 84ms/step\n","(250, 250)\n","1/1 [==============================] - 0s 84ms/step\n","(250, 250)\n","1/1 [==============================] - 0s 84ms/step\n","(250, 250)\n","1/1 [==============================] - 0s 84ms/step\n","(250, 250)\n","1/1 [==============================] - 0s 84ms/step\n","(250, 250)\n","1/1 [==============================] - 0s 84ms/step\n","(250, 250)\n","1/1 [==============================] - 0s 84ms/step\n","(250, 250)\n","1/1 [==============================] - 0s 84ms/step\n","(250, 250)\n","1/1 [==============================] - 0s 85ms/step\n","(250, 250)\n","1/1 [==============================] - 0s 84ms/step\n","(250, 250)\n","1/1 [==============================] - 0s 84ms/step\n","(250, 250)\n","1/1 [==============================] - 0s 84ms/step\n","(250, 250)\n","1/1 [==============================] - 0s 84ms/step\n","(250, 250)\n","1/1 [==============================] - 0s 84ms/step\n","(250, 250)\n","1/1 [==============================] - 0s 84ms/step\n","(250, 250)\n","1/1 [==============================] - 0s 85ms/step\n","(250, 250)\n","1/1 [==============================] - 0s 84ms/step\n","(250, 250)\n","1/1 [==============================] - 0s 84ms/step\n","(250, 250)\n","1/1 [==============================] - 0s 84ms/step\n","(250, 250)\n","1/1 [==============================] - 0s 84ms/step\n","(250, 250)\n","1/1 [==============================] - 0s 84ms/step\n","(250, 250)\n","1/1 [==============================] - 0s 84ms/step\n","(250, 250)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"WKsHcCY-DS8n"},"source":["## Create Plot"]},{"cell_type":"code","metadata":{"id":"CbhcK5xYBpct","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629473352520,"user_tz":-330,"elapsed":4153,"user":{"displayName":"Rik Das","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgTTiRJEQsnHczOK7jiY2UY6jbgb3hPYBY2YaRJ=s64","userId":"00444844359278086917"}},"outputId":"949f7875-1db8-4b42-d845-2d9acbec5900"},"source":["import os\n","import pandas as pd\n","import math\n","import numpy as np\n","from PIL import Image\n","\n","from plotly import tools\n","import plotly.plotly as py\n","import plotly.graph_objs as go\n","\n","filename = \"Saved_Model/history.csv\"\n","# Open the history file that stores the training accuracy and loss.\n","history = pd.read_csv(filename, header=0, low_memory=False)\n","history_array = history.values\n","epochs = history_array[:, 0]\n","training_accuracy = history_array[:, 1]\n","training_loss = history_array[:, 2]\n","\n","py.sign_in('VikramShenoy','x1Un4yD3HDRT838vRkFA')\n","\n","# Generate accuracy and loss trace.\n","trace0 = go.Scatter(\n","x = epochs,\n","y = training_accuracy,\n","mode = \"lines\",\n","name = \"Training Accuracy\"\n",")\n","\n","trace1 = go.Scatter(\n","x = epochs,\n","y = training_loss,\n","mode = \"lines\",\n","name = \"Training Loss\"\n",")\n","# Create Training Accuracy vs Loss Graph\n","data = go.Data([trace0, trace1])\n","layout = go.Layout(title=\"Training Accuracy vs Loss\")\n","fig = go.Figure(data=data, layout=layout)\n","fig['layout']['xaxis'].update(title=\"Number of Epochs\", range = [min(epochs), max(epochs)], dtick=len(epochs)/10, showline = True, zeroline=True,  mirror='ticks', linecolor='#636363', linewidth=2)\n","fig['layout']['yaxis'].update(title=\"Training Accuracy / Loss\", range = [0, 1], dtick=0.1, showline = True, zeroline=True, mirror='ticks',linecolor='#636363',linewidth=2)\n","py.image.save_as(fig, filename=\"Training_Graph.png\")\n","\n","print \"Training Graph Created\""],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python2.7/dist-packages/plotly/graph_objs/_deprecations.py:39: DeprecationWarning:\n","\n","plotly.graph_objs.Data is deprecated.\n","Please replace it with a list or tuple of instances of the following types\n","  - plotly.graph_objs.Scatter\n","  - plotly.graph_objs.Bar\n","  - plotly.graph_objs.Area\n","  - plotly.graph_objs.Histogram\n","  - etc.\n","\n","\n"],"name":"stderr"},{"output_type":"stream","text":["Training Graph Created\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ocRpmI_1BqKV"},"source":[""],"execution_count":null,"outputs":[]}]}